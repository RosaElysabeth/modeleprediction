{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e4bac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "import shap\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9dd1a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    start_time = time.time()  # Recording start time\n",
    "\n",
    "    # Loading data\n",
    "    print(\"Loading data...\")\n",
    "    data = pd.read_excel('./etat_securite.xlsx')\n",
    "    print(\"Data loaded successfully.\")\n",
    "\n",
    "    df = data.copy()\n",
    "\n",
    "    # Data preprocessing\n",
    "    features = df.drop('Situation_Surpoids', axis=1)\n",
    "    target = df['Situation_Surpoids']\n",
    "\n",
    "    # Encoding\n",
    "    code = {'Acceptable(Normale)': 1, 'PrÃ©caire': 2, 'Alarmante(Alerte)': 3, 'Critique(Urgence)': 4}\n",
    "    for col in df.select_dtypes('object').columns:\n",
    "        df.loc[:, col] = df[col].replace(code)\n",
    "\n",
    "    # Imputing missing values for all columns with 'most_frequent' strategy\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "    df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "    # Splitting data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_imputed, target, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(f\"Debug - Data Shape: {df.shape}\")\n",
    "    print(f\"Debug - X_train Shape: {X_train.shape}, y_train Shape: {y_train.shape}\")\n",
    "\n",
    "    # Creating and training the model\n",
    "    print(\"Training the model...\")\n",
    "    food_security_model = SVC(kernel='linear', C=1)\n",
    "    # Print unique values in y_train\n",
    "    print(\"Unique values in y_train:\", y_train.unique())\n",
    "\n",
    "    food_security_model.fit(X_train, y_train)\n",
    "    print(\"Model trained successfully.\")\n",
    "\n",
    "    # Initializing SHAP with the trained model\n",
    "    print(\"Initializing SHAP...\")\n",
    "    explainer = shap.Explainer(food_security_model, X_train)\n",
    "    print(\"SHAP initialized successfully.\")\n",
    "\n",
    "    # Recording end time and calculating duration\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Model loading time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    return food_security_model, explainer, X_train, y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82ee6c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, features):\n",
    "    food_security_model = model\n",
    "    prediction = food_security_model.predict(features)[0]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df5e6c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_shap(model, features):\n",
    "    _, explainer = model\n",
    "    features = features.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Calculating SHAP values\n",
    "    shap_values = explainer.shap_values(features)\n",
    "\n",
    "    # print(shap_values)\n",
    "\n",
    "    return shap_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41f1baba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map region names to numeric values\n",
    "def map_region_to_numeric(region_name):\n",
    "    region_mapping = {\n",
    "        \"madagascar\": 0,\n",
    "        \"diana\": 1,\n",
    "        \"sava\": 2,\n",
    "        \"itasy\": 3,\n",
    "        \"analamanga\": 4,\n",
    "        \"vakinankaratra\": 5,\n",
    "        \"bongolava\": 6,\n",
    "        \"sofia\": 7,\n",
    "        \"boeny\": 8,\n",
    "        \"betsiboka\": 9,\n",
    "        \"melaky\": 10,\n",
    "        \"alaotra-mangoro\": 11,\n",
    "        \"antsinana\": 12,\n",
    "        \"analanjirofo\": 13,\n",
    "        \"ambatosoa\": 14,\n",
    "        \"amoron'i mania\": 15,\n",
    "        \"vatovavy\": 16,\n",
    "        \"fitovinany\": 17,\n",
    "        \"haute matsiatra\": 18,\n",
    "        \"atsimo-atsinanana\": 19,\n",
    "        \"ihorombe\": 20,\n",
    "        \"menabe\": 21,\n",
    "        \"atsimo-andrefana\": 22,\n",
    "        \"androy\": 23\n",
    "    }\n",
    "\n",
    "    # Convert region to lowercase before looking in the dictionary\n",
    "    region_name_lower = region_name.lower()\n",
    "\n",
    "    # Return the corresponding numeric value if it exists, otherwise return -1 or a default value\n",
    "    return region_mapping.get(region_name_lower, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3096d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_shap(feature_names, shap_values, region_name):\n",
    "    interpretations = []\n",
    "\n",
    "    if shap_values.ndim == 1:\n",
    "        for i, val in enumerate(shap_values):\n",
    "            feature_name = feature_names[i]\n",
    "            interpretations.append(\n",
    "                f\"For the region {region_name}, the value of the feature '{feature_name}' has an impact of {val:.4f} on the prediction.\"\n",
    "            )\n",
    "    else:\n",
    "        interpretations.append(\n",
    "            f\"For the region {region_name}, the value of the feature has multiple components and cannot be interpreted simply. The components are: {shap_value.tolist()}\"\n",
    "        )\n",
    "\n",
    "    return interpretations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64b5d7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of Phenomena\n",
      "Loading data...\n",
      "Data loaded successfully.\n",
      "Debug - Data Shape: (298, 12)\n",
      "Debug - X_train Shape: (238, 12), y_train Shape: (238,)\n",
      "Training the model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: unknown. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction of Phenomena\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model, explainer, X_train, y_train \u001b[38;5;241m=\u001b[39m load_model()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# User interface to input features\u001b[39;00m\n\u001b[0;32m      7\u001b[0m region_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the region:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 33\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining the model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m food_security_model \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m food_security_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel trained successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Initializing SHAP with the trained model\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:199\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    191\u001b[0m         X,\n\u001b[0;32m    192\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    197\u001b[0m     )\n\u001b[1;32m--> 199\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_targets(y)\n\u001b[0;32m    201\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m    202\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[0;32m    203\u001b[0m )\n\u001b[0;32m    204\u001b[0m solver_type \u001b[38;5;241m=\u001b[39m LIBSVM_IMPL\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:743\u001b[0m, in \u001b[0;36mBaseSVC._validate_targets\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_targets\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[0;32m    742\u001b[0m     y_ \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 743\u001b[0m     check_classification_targets(y)\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;28mcls\u001b[39m, y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight_ \u001b[38;5;241m=\u001b[39m compute_class_weight(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, y\u001b[38;5;241m=\u001b[39my_)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:215\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    207\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    214\u001b[0m ]:\n\u001b[1;32m--> 215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: unknown. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "print(\"Prediction of Phenomena\")\n",
    "\n",
    "# Load the model\n",
    "model, explainer, X_train, y_train = load_model()\n",
    "\n",
    "# User interface to input features\n",
    "region_name = input(\"Enter the region:\")\n",
    "region_numeric = map_region_to_numeric(region_name)\n",
    "\n",
    "# Check if the region is valid\n",
    "if region_numeric == -1:\n",
    "    print(\"The entered region is not valid. Please enter a valid region.\")\n",
    "    return\n",
    "\n",
    "date = input(\"Enter the date:\")\n",
    "\n",
    "# Extract features from date\n",
    "year = int(date.split('-')[0])\n",
    "month = int(date.split('-')[1])\n",
    "day = int(date.split('-')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c0b989b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 53\u001b[0m\n\u001b[0;32m     38\u001b[0m features3 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATE\u001b[39m\u001b[38;5;124m\"\u001b[39m: [year],\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREGION\u001b[39m\u001b[38;5;124m\"\u001b[39m: [region_numeric],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPourcentage_membres_menages_lieu_lavage_mains_eau_savon_detergent\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m26\u001b[39m]\n\u001b[0;32m     51\u001b[0m })\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Use X_train column names to ensure consistency\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m features1\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m     56\u001b[0m prediction1 \u001b[38;5;241m=\u001b[39m predict(model, features1)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the 'year' variable\n",
    "year = 2023 \n",
    "# Define the 'region_numeric' variable\n",
    "region_name = \"madagascar\"  # You can set the desired region name\n",
    "\n",
    "# Button to make the prediction\n",
    "start_prediction_time = time.time()  # Record prediction start time\n",
    "\n",
    "# Preprocess features (excluding \"Overweight_Situation\")\n",
    "features1 = pd.DataFrame({\n",
    "        \"DATE\": [year],\n",
    "        \"REGION\": [region_numeric],\n",
    "        \"Situation_Surpoids\": [3],\n",
    "        \"Situation_MC\": [1], \n",
    "        \"Situation_MA\": [2],\n",
    "        \"Proportion_population_insuffisance_calorique\": [5],\n",
    "        \"EPIDEMOLOGIE\": [60],\n",
    "        \"Taux_couverture_vaccinale_complete\": [28],\n",
    "        \"Taille_moyenne_menages_Individus\": [4],\n",
    "        \"Pourcentage_femmes_couvertes_assurance_maladie\": [2],\n",
    "        \"Pourcentage_membres_menages_toilettes_ameliorees\": [20],\n",
    "        \"Pourcentage_membres_menages_lieu_lavage_mains_eau_savon_detergent\": [26]\n",
    "    })\n",
    "features2 = pd.DataFrame({\n",
    "    \"DATE\": [year],\n",
    "    \"REGION\": [region_numeric],\n",
    "    \"Situation_Surpoids\": [2],\n",
    "    \"Situation_MC\": [1], \n",
    "    \"Situation_MA\": [4],\n",
    "    \"Proportion_population_insuffisance_calorique\": [70],\n",
    "    \"EPIDEMOLOGIE\": [70],\n",
    "    \"Taux_couverture_vaccinale_complete\": [18],\n",
    "    \"Taille_moyenne_menages_Individus\": [5],\n",
    "    \"Pourcentage_femmes_couvertes_assurance_maladie\": [0.5],\n",
    "    \"Pourcentage_membres_menages_toilettes_ameliorees\": [8],\n",
    "    \"Pourcentage_membres_menages_lieu_lavage_mains_eau_savon_detergent\": [2]\n",
    "})\n",
    "features3 = pd.DataFrame({\n",
    "    \"DATE\": [year],\n",
    "    \"REGION\": [region_numeric],\n",
    "    \"Situation_Surpoids\": [4],\n",
    "    \"Situation_MC\": [1], \n",
    "    \"Situation_MA\": [3],\n",
    "    \"Proportion_population_insuffisance_calorique\": [40],\n",
    "    \"EPIDEMOLOGIE\": [20],\n",
    "    \"Taux_couverture_vaccinale_complete\": [52],\n",
    "    \"Taille_moyenne_menages_Individus\": [4],\n",
    "    \"Pourcentage_femmes_couvertes_assurance_maladie\": [3],\n",
    "    \"Pourcentage_membres_menages_toilettes_ameliorees\": [6],\n",
    "    \"Pourcentage_membres_menages_lieu_lavage_mains_eau_savon_detergent\": [26]\n",
    "})\n",
    "# Use X_train column names to ensure consistency\n",
    "features1.columns = X_train.columns\n",
    "\n",
    "# Make predictions\n",
    "prediction1 = predict(model, features1)\n",
    "prediction2 = predict(model, features2)\n",
    "prediction3 = predict(model, features3)\n",
    "\n",
    "# Display predictions\n",
    "print(f\"Prediction of Underweight: {prediction1}\")\n",
    "print(f\"Prediction of Chronic Malnutrition: {prediction2}\")\n",
    "print(f\"Prediction of Acute Malnutrition: {prediction3}\")\n",
    "\n",
    "# Calculate and display SHAP values\n",
    "shap_values = calculate_shap((model, explainer), features1)\n",
    "\n",
    " # Record end time of prediction and calculate duration\n",
    "end_prediction_time = time.time()\n",
    "elapsed_prediction_time = end_prediction_time - start_prediction_time\n",
    "print(f\"Prediction time: {elapsed_prediction_time:.4f} seconds\")\n",
    "\n",
    "# Get descending order of feature indices by impact\n",
    "feature_order = list(reversed(np.argsort(shap_values[0])))\n",
    "\n",
    "print(f\"Debug - Feature Order: {feature_order}\")\n",
    "\n",
    "#SHAP Values\n",
    "print(\"SHAP Values:\")\n",
    "print(f\"{shap_values}\")\n",
    "\n",
    "# Display SHAP results with comments suitable for nutritionists\n",
    "print(\"Interpretation of SHAP Values:\")\n",
    "\n",
    "feature_names = features1.columns \n",
    "\n",
    "for feature_index in feature_order[0]:\n",
    "    if 0 <= feature_index < len(shap_values[0]):\n",
    "        feature_name = feature_names[feature_index]  \n",
    "        shap_value = shap_values[0][feature_index]\n",
    "\n",
    "        print(f\"Debug - Feature Index: {feature_index}, Feature Name: {feature_name}, SHAP Value Shape: {shap_value.shape}\")\n",
    "\n",
    "        interpretation = interpret_shap(feature_names, shap_value, region_name)\n",
    "\n",
    "        print(interpretation)\n",
    "\n",
    "        print(f\"Debug - All SHAP Values for {feature_name}:\\n{shap_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772da353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
